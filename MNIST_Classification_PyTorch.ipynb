{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfWySeub-u9I",
        "outputId": "67e4491f-6524-4d6c-bcb8-18a350d34a5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['image', 'label'],\n",
              "        num_rows: 60000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['image', 'label'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"mnist\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "aYDPiYuKG-Vs"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = dataset['train']['image']\n",
        "train_label = dataset['train']['label']\n",
        "\n",
        "# Convert the list of images to a NumPy array\n",
        "train_images_array = np.array([np.array(img) for img in train_images])\n",
        "\n",
        "# Reshape the array to flatten each image\n",
        "train_images_flattened = train_images_array.reshape(len(train_images_array), -1)\n",
        "\n",
        "# Create a Pandas DataFrame from the flattened images\n",
        "train_df = pd.DataFrame(train_images_flattened)"
      ],
      "metadata": {
        "id": "4Hzq2iMvHw73"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = dataset['test']['image']\n",
        "test_label = dataset['test']['label']\n",
        "\n",
        "# Convert the list of images to a NumPy array\n",
        "test_images_array = np.array([np.array(img) for img in test_images])\n",
        "\n",
        "# Reshape the array to flatten each image\n",
        "test_images_flattened = test_images_array.reshape(len(test_images_array), -1)\n",
        "\n",
        "# Create a Pandas DataFrame from the flattened images\n",
        "test_df = pd.DataFrame(test_images_flattened)"
      ],
      "metadata": {
        "id": "skvvURQGHklM"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "2SxMCEluHKiO"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Clf(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer1 = nn.Linear(in_features=784,out_features=128)\n",
        "    self.layer2 = nn.Linear(in_features=128,out_features=64)\n",
        "    self.layer3 = nn.Linear(in_features=64,out_features=10)\n",
        "    self.r = nn.ReLU()\n",
        "  def forward(self,x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.r(x)\n",
        "    x = self.layer2(x)\n",
        "    x = self.r(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.r(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "rzhkjX5ZIqE1"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = Clf()\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(clf.parameters(),lr= 0.001)"
      ],
      "metadata": {
        "id": "rOd1CFMcJwZ1"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc"
      ],
      "metadata": {
        "id": "A_XEAgPZb9PY"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = torch.Tensor(train_df.to_numpy())\n",
        "test = torch.Tensor(test_df.to_numpy())\n",
        "trainl = torch.Tensor(train_label).long()\n",
        "testl = torch.Tensor(test_label).long()"
      ],
      "metadata": {
        "id": "MSi-TqvmnZp-"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "for epoch in range(epochs):\n",
        "    clf.train()\n",
        "    train_logits = clf(train)\n",
        "    train_pred = torch.softmax(train_logits, dim=1).argmax(dim=1)\n",
        "    loss = loss_func(train_logits,trainl)\n",
        "    accuracy = accuracy_fn(train_pred,trainl)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    clf.eval()\n",
        "    with torch.inference_mode():\n",
        "      test_logits = clf(test)\n",
        "      test_pred = torch.softmax(test_logits, dim=1).argmax(dim=1)\n",
        "      test_loss = loss_func(test_logits,testl)\n",
        "      test_accuracy = accuracy_fn(test_pred,testl)\n",
        "    if epoch % 10 == 0:\n",
        "      print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {accuracy:.2f}% | Test Loss: {test_loss:.5f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
        "print('Finished Training')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rj63lwD4KJps",
        "outputId": "3c8ea570-df5b-4b18-fd88-c572b6113c00"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 0.78421, Accuracy: 77.33% | Test Loss: 0.80393, Test Accuracy: 77.13%\n",
            "Epoch: 10 | Loss: 0.77707, Accuracy: 77.52% | Test Loss: 0.79969, Test Accuracy: 77.15%\n",
            "Epoch: 20 | Loss: 0.77080, Accuracy: 77.66% | Test Loss: 0.79645, Test Accuracy: 77.16%\n",
            "Epoch: 30 | Loss: 0.76520, Accuracy: 77.84% | Test Loss: 0.79353, Test Accuracy: 77.20%\n",
            "Epoch: 40 | Loss: 0.76021, Accuracy: 78.00% | Test Loss: 0.79071, Test Accuracy: 77.34%\n",
            "Epoch: 50 | Loss: 0.75567, Accuracy: 78.09% | Test Loss: 0.78836, Test Accuracy: 77.40%\n",
            "Epoch: 60 | Loss: 0.75151, Accuracy: 78.18% | Test Loss: 0.78622, Test Accuracy: 77.45%\n",
            "Epoch: 70 | Loss: 0.74772, Accuracy: 78.30% | Test Loss: 0.78454, Test Accuracy: 77.54%\n",
            "Epoch: 80 | Loss: 0.74418, Accuracy: 78.42% | Test Loss: 0.78334, Test Accuracy: 77.58%\n",
            "Epoch: 90 | Loss: 0.74079, Accuracy: 78.53% | Test Loss: 0.78233, Test Accuracy: 77.67%\n",
            "Epoch: 100 | Loss: 0.73778, Accuracy: 78.59% | Test Loss: 0.78137, Test Accuracy: 77.69%\n",
            "Epoch: 110 | Loss: 0.73504, Accuracy: 78.66% | Test Loss: 0.78061, Test Accuracy: 77.75%\n",
            "Epoch: 120 | Loss: 0.73254, Accuracy: 78.72% | Test Loss: 0.78000, Test Accuracy: 77.75%\n",
            "Epoch: 130 | Loss: 0.73024, Accuracy: 78.79% | Test Loss: 0.77933, Test Accuracy: 77.78%\n",
            "Epoch: 140 | Loss: 0.72809, Accuracy: 78.84% | Test Loss: 0.77898, Test Accuracy: 77.85%\n",
            "Epoch: 150 | Loss: 0.72611, Accuracy: 78.88% | Test Loss: 0.77862, Test Accuracy: 77.92%\n",
            "Epoch: 160 | Loss: 0.72429, Accuracy: 78.94% | Test Loss: 0.77874, Test Accuracy: 77.90%\n",
            "Epoch: 170 | Loss: 0.72261, Accuracy: 78.99% | Test Loss: 0.77870, Test Accuracy: 77.95%\n",
            "Epoch: 180 | Loss: 0.72108, Accuracy: 79.02% | Test Loss: 0.77893, Test Accuracy: 77.93%\n",
            "Epoch: 190 | Loss: 0.71967, Accuracy: 79.07% | Test Loss: 0.77913, Test Accuracy: 77.96%\n",
            "Epoch: 200 | Loss: 0.71834, Accuracy: 79.11% | Test Loss: 0.77939, Test Accuracy: 77.93%\n",
            "Epoch: 210 | Loss: 0.71705, Accuracy: 79.13% | Test Loss: 0.77997, Test Accuracy: 77.90%\n",
            "Epoch: 220 | Loss: 0.71584, Accuracy: 79.16% | Test Loss: 0.78005, Test Accuracy: 77.88%\n",
            "Epoch: 230 | Loss: 0.71471, Accuracy: 79.19% | Test Loss: 0.78035, Test Accuracy: 77.91%\n",
            "Epoch: 240 | Loss: 0.71362, Accuracy: 79.21% | Test Loss: 0.78073, Test Accuracy: 77.91%\n",
            "Epoch: 250 | Loss: 0.71266, Accuracy: 79.23% | Test Loss: 0.78114, Test Accuracy: 77.93%\n",
            "Epoch: 260 | Loss: 0.71174, Accuracy: 79.26% | Test Loss: 0.78157, Test Accuracy: 77.97%\n",
            "Epoch: 270 | Loss: 0.71088, Accuracy: 79.29% | Test Loss: 0.78184, Test Accuracy: 77.96%\n",
            "Epoch: 280 | Loss: 0.71006, Accuracy: 79.31% | Test Loss: 0.78222, Test Accuracy: 78.02%\n",
            "Epoch: 290 | Loss: 0.70931, Accuracy: 79.32% | Test Loss: 0.78269, Test Accuracy: 78.04%\n",
            "Epoch: 300 | Loss: 0.70862, Accuracy: 79.34% | Test Loss: 0.78334, Test Accuracy: 78.05%\n",
            "Epoch: 310 | Loss: 0.70795, Accuracy: 79.35% | Test Loss: 0.78421, Test Accuracy: 78.09%\n",
            "Epoch: 320 | Loss: 0.70735, Accuracy: 79.35% | Test Loss: 0.78488, Test Accuracy: 78.08%\n",
            "Epoch: 330 | Loss: 0.70677, Accuracy: 79.37% | Test Loss: 0.78569, Test Accuracy: 78.09%\n",
            "Epoch: 340 | Loss: 0.70626, Accuracy: 79.39% | Test Loss: 0.78646, Test Accuracy: 78.11%\n",
            "Epoch: 350 | Loss: 0.70578, Accuracy: 79.38% | Test Loss: 0.78720, Test Accuracy: 78.13%\n",
            "Epoch: 360 | Loss: 0.70529, Accuracy: 79.40% | Test Loss: 0.78808, Test Accuracy: 78.14%\n",
            "Epoch: 370 | Loss: 0.70484, Accuracy: 79.40% | Test Loss: 0.78863, Test Accuracy: 78.12%\n",
            "Epoch: 380 | Loss: 0.70442, Accuracy: 79.41% | Test Loss: 0.78939, Test Accuracy: 78.14%\n",
            "Epoch: 390 | Loss: 0.70406, Accuracy: 79.41% | Test Loss: 0.79014, Test Accuracy: 78.12%\n",
            "Epoch: 400 | Loss: 0.70372, Accuracy: 79.42% | Test Loss: 0.79095, Test Accuracy: 78.10%\n",
            "Epoch: 410 | Loss: 0.70337, Accuracy: 79.41% | Test Loss: 0.79228, Test Accuracy: 78.07%\n",
            "Epoch: 420 | Loss: 0.70302, Accuracy: 79.41% | Test Loss: 0.79303, Test Accuracy: 78.06%\n",
            "Epoch: 430 | Loss: 0.70273, Accuracy: 79.44% | Test Loss: 0.79358, Test Accuracy: 78.04%\n",
            "Epoch: 440 | Loss: 0.70248, Accuracy: 79.46% | Test Loss: 0.79442, Test Accuracy: 78.05%\n",
            "Epoch: 450 | Loss: 0.70223, Accuracy: 79.44% | Test Loss: 0.79566, Test Accuracy: 78.07%\n",
            "Epoch: 460 | Loss: 0.70198, Accuracy: 79.46% | Test Loss: 0.79639, Test Accuracy: 78.10%\n",
            "Epoch: 470 | Loss: 0.70178, Accuracy: 79.47% | Test Loss: 0.79697, Test Accuracy: 78.10%\n",
            "Epoch: 480 | Loss: 0.70154, Accuracy: 79.48% | Test Loss: 0.79790, Test Accuracy: 78.10%\n",
            "Epoch: 490 | Loss: 0.70136, Accuracy: 79.48% | Test Loss: 0.79886, Test Accuracy: 78.10%\n",
            "Epoch: 500 | Loss: 0.70118, Accuracy: 79.48% | Test Loss: 0.79930, Test Accuracy: 78.09%\n",
            "Epoch: 510 | Loss: 0.70099, Accuracy: 79.47% | Test Loss: 0.80058, Test Accuracy: 78.08%\n",
            "Epoch: 520 | Loss: 0.70086, Accuracy: 79.47% | Test Loss: 0.80093, Test Accuracy: 78.07%\n",
            "Epoch: 530 | Loss: 0.70067, Accuracy: 79.49% | Test Loss: 0.80215, Test Accuracy: 78.07%\n",
            "Epoch: 540 | Loss: 0.70052, Accuracy: 79.48% | Test Loss: 0.80312, Test Accuracy: 78.05%\n",
            "Epoch: 550 | Loss: 0.70038, Accuracy: 79.50% | Test Loss: 0.80406, Test Accuracy: 78.04%\n",
            "Epoch: 560 | Loss: 0.70024, Accuracy: 79.48% | Test Loss: 0.80486, Test Accuracy: 78.01%\n",
            "Epoch: 570 | Loss: 0.70010, Accuracy: 79.48% | Test Loss: 0.80557, Test Accuracy: 78.03%\n",
            "Epoch: 580 | Loss: 0.69999, Accuracy: 79.53% | Test Loss: 0.80628, Test Accuracy: 78.06%\n",
            "Epoch: 590 | Loss: 0.69986, Accuracy: 79.51% | Test Loss: 0.80747, Test Accuracy: 78.04%\n",
            "Epoch: 600 | Loss: 0.69974, Accuracy: 79.53% | Test Loss: 0.80805, Test Accuracy: 77.99%\n",
            "Epoch: 610 | Loss: 0.69965, Accuracy: 79.52% | Test Loss: 0.80879, Test Accuracy: 78.01%\n",
            "Epoch: 620 | Loss: 0.69952, Accuracy: 79.51% | Test Loss: 0.80994, Test Accuracy: 78.04%\n",
            "Epoch: 630 | Loss: 0.69941, Accuracy: 79.52% | Test Loss: 0.81011, Test Accuracy: 78.04%\n",
            "Epoch: 640 | Loss: 0.69932, Accuracy: 79.54% | Test Loss: 0.81127, Test Accuracy: 78.03%\n",
            "Epoch: 650 | Loss: 0.69926, Accuracy: 79.51% | Test Loss: 0.81159, Test Accuracy: 78.04%\n",
            "Epoch: 660 | Loss: 0.69920, Accuracy: 79.53% | Test Loss: 0.81276, Test Accuracy: 78.03%\n",
            "Epoch: 670 | Loss: 0.69910, Accuracy: 79.55% | Test Loss: 0.81378, Test Accuracy: 78.03%\n",
            "Epoch: 680 | Loss: 0.69897, Accuracy: 79.52% | Test Loss: 0.81431, Test Accuracy: 78.05%\n",
            "Epoch: 690 | Loss: 0.69887, Accuracy: 79.55% | Test Loss: 0.81509, Test Accuracy: 78.06%\n",
            "Epoch: 700 | Loss: 0.69881, Accuracy: 79.55% | Test Loss: 0.81546, Test Accuracy: 78.05%\n",
            "Epoch: 710 | Loss: 0.69870, Accuracy: 79.55% | Test Loss: 0.81625, Test Accuracy: 78.05%\n",
            "Epoch: 720 | Loss: 0.69857, Accuracy: 79.56% | Test Loss: 0.81698, Test Accuracy: 78.05%\n",
            "Epoch: 730 | Loss: 0.69845, Accuracy: 79.56% | Test Loss: 0.81839, Test Accuracy: 78.04%\n",
            "Epoch: 740 | Loss: 0.69839, Accuracy: 79.54% | Test Loss: 0.81821, Test Accuracy: 78.05%\n",
            "Epoch: 750 | Loss: 0.69834, Accuracy: 79.58% | Test Loss: 0.81846, Test Accuracy: 78.07%\n",
            "Epoch: 760 | Loss: 0.69827, Accuracy: 79.53% | Test Loss: 0.81978, Test Accuracy: 78.05%\n",
            "Epoch: 770 | Loss: 0.69822, Accuracy: 79.53% | Test Loss: 0.82037, Test Accuracy: 78.04%\n",
            "Epoch: 780 | Loss: 0.69817, Accuracy: 79.55% | Test Loss: 0.82116, Test Accuracy: 78.05%\n",
            "Epoch: 790 | Loss: 0.69813, Accuracy: 79.58% | Test Loss: 0.82151, Test Accuracy: 78.06%\n",
            "Epoch: 800 | Loss: 0.69805, Accuracy: 79.55% | Test Loss: 0.82192, Test Accuracy: 78.05%\n",
            "Epoch: 810 | Loss: 0.69800, Accuracy: 79.57% | Test Loss: 0.82176, Test Accuracy: 78.09%\n",
            "Epoch: 820 | Loss: 0.69792, Accuracy: 79.57% | Test Loss: 0.82319, Test Accuracy: 78.03%\n",
            "Epoch: 830 | Loss: 0.69786, Accuracy: 79.57% | Test Loss: 0.82360, Test Accuracy: 78.05%\n",
            "Epoch: 840 | Loss: 0.69781, Accuracy: 79.59% | Test Loss: 0.82443, Test Accuracy: 78.06%\n",
            "Epoch: 850 | Loss: 0.69779, Accuracy: 79.54% | Test Loss: 0.82442, Test Accuracy: 78.07%\n",
            "Epoch: 860 | Loss: 0.69776, Accuracy: 79.59% | Test Loss: 0.82451, Test Accuracy: 78.07%\n",
            "Epoch: 870 | Loss: 0.69773, Accuracy: 79.59% | Test Loss: 0.82601, Test Accuracy: 78.10%\n",
            "Epoch: 880 | Loss: 0.69766, Accuracy: 79.59% | Test Loss: 0.82615, Test Accuracy: 78.09%\n",
            "Epoch: 890 | Loss: 0.69759, Accuracy: 79.59% | Test Loss: 0.82656, Test Accuracy: 78.11%\n",
            "Epoch: 900 | Loss: 0.69755, Accuracy: 79.57% | Test Loss: 0.82720, Test Accuracy: 78.09%\n",
            "Epoch: 910 | Loss: 0.69750, Accuracy: 79.59% | Test Loss: 0.82809, Test Accuracy: 78.05%\n",
            "Epoch: 920 | Loss: 0.69747, Accuracy: 79.61% | Test Loss: 0.82812, Test Accuracy: 78.07%\n",
            "Epoch: 930 | Loss: 0.69743, Accuracy: 79.60% | Test Loss: 0.82862, Test Accuracy: 78.09%\n",
            "Epoch: 940 | Loss: 0.69738, Accuracy: 79.58% | Test Loss: 0.82927, Test Accuracy: 78.07%\n",
            "Epoch: 950 | Loss: 0.69735, Accuracy: 79.58% | Test Loss: 0.83021, Test Accuracy: 78.10%\n",
            "Epoch: 960 | Loss: 0.69731, Accuracy: 79.59% | Test Loss: 0.83030, Test Accuracy: 78.08%\n",
            "Epoch: 970 | Loss: 0.69725, Accuracy: 79.59% | Test Loss: 0.83053, Test Accuracy: 78.09%\n",
            "Epoch: 980 | Loss: 0.69723, Accuracy: 79.58% | Test Loss: 0.83079, Test Accuracy: 78.08%\n",
            "Epoch: 990 | Loss: 0.69719, Accuracy: 79.60% | Test Loss: 0.83186, Test Accuracy: 78.08%\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def resize_image(image_path, output_path, width, height):\n",
        "    # Open the image file\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Resize the image\n",
        "    resized_image = image.resize((width, height))\n",
        "\n",
        "    # Save the resized image\n",
        "    resized_image.save(output_path)\n",
        "\n",
        "# Example usage\n",
        "input_image_path = \"/content/Screenshot 2024-04-18 214216.png\"\n",
        "output_image_path = \"/content/Screenshot 2024-04-18 214216_resized.png\"\n",
        "target_width = 28\n",
        "target_height = 28\n",
        "\n",
        "resize_image(input_image_path, output_image_path, target_width, target_height)\n"
      ],
      "metadata": {
        "id": "3NqnG1MWlzLd"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open(input_image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "YsrbEbchwCDV",
        "outputId": "a6e71cb4-8204-473b-b58e-29b6bb75519a"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=318x305>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAT4AAAExCAYAAADlbs7lAAAEw0lEQVR4nO3cQY7jIBRAQRj1/a/sucFkOt0GnFe1jRSxesJ87DnGuAZAyJ/dCwBYTfiAHOEDcoQPyBE+IEf4gBzhA3KED8gRPiBH+IAc4QNyhA/IET4gR/iAHOEDcoQPyBE+IEf4gBzhA3KED8gRPiBH+IAc4QNyhA/IET4gR/iAHOEDcoQPyBE+IEf4gBzhA3KED8gRPiBH+IAc4QNyhA/IET4gR/iAHOEDcoQPyBE+IEf4gBzhA3KED8gRPiBH+IAc4QNyhA/IET4gR/iAHOEDcoQPyBE+IEf4gBzhA3KED8gRPiBH+IAc4QNyhA/IET4g52v3Ahjjuq5//j7nXLQSaLDjA3KED8gRPiBH+IAc4QNyhA/IET4gR/iAHBeYuZ0L2pzGjg/IEb4HeLVjAr5H+IAc4QNyhA/IET4gR/iAHOEDcoQPyBG+A3hzAdYSPiBH+IAc4XsIr63B7xE+IEf4gBzhA3KED8gRPiBH+IAc4XsQV1rgdwjfIby2BusIH5AjfECO8AE5wvcwBhzwc8IH5Agf29nFsprwHcSVFlhD+B7IDgl+RviAHOEDcoTvoTzuwvuE7zAGHHA/4QNyhI/b2cVyGuF7MOd88B7hO5AdEtxL+IAc4QNyhO9QHnfhPsIH5AgfRzChZiXhA3KE72DO+eAewgfkCB+QI3xAjvBxDJNdVhE+IEf4WMKEmpMIH5AjfECO8AE5wgfkCB+QI3wsY7LLKYQPyBE+IEf4gBzhA3KED8gRPiBH+IAc4QNyhA/IET4gR/iAHOEDcoQPyBE+IEf4gBzhA3KED8gRPiBH+IAc4QNyhA/IET4gR/iAHOEDcoQPyBE+IOdr9wL4HNd1HfEfTzPn3L2EHOHjLcVA8TmE7+EECL7PGR+QI3xAjvABOcIH5AgfkGOqyzJzzpdTaHfaWEH4uIWAcTLh+zCCA68J3+GEDH6f4QaQI3xAjvABOcIH5AgfkCN8QI7wATnCB+QIH5AjfECO8AE5wgfkCB+QI3xAjvABOcIH5AgfkCN8QI7wATnCB+QIH5AjfECO8AE5wgfkCB+QI3xAjvABOcIH5AgfkCN8QI7wATnCB+QIH5AjfECO8AE5wgfkCB+QI3xAjvABOcIH5AgfkCN8LHNd1+4lwBhD+IAg4QNyhA/IET4gR/iAHOEDcoQPyBE+jjHn3L0EIoQPyBE+IEf4gBzhA3KED8gRPiBH+IAc4QNyhI8lfISUkwgfkCN8QI7wATnCx+2c73Ea4QNyhA/IET4gR/g4go+QspLwATnCB+QIH5AjfNzqf+7wOd9jNeEDcoQPyBE+IEf4gBzhA3KEj9v4KgunEj4gR/jYyh0+dhA+IEf4uIXzPU4mfECO8AE5wgfkCB/bmOiyi/ABOcIH5AgfkCN8bOF8j52ED8iZYwxX7IEUOz4gR/iAHOEDcoQPyBE+IEf4gBzhA3KED8gRPiBH+IAc4QNyhA/IET4gR/iAHOEDcoQPyBE+IEf4gBzhA3KED8gRPiBH+IAc4QNyhA/IET4gR/iAHOEDcoQPyBE+IEf4gBzhA3KED8gRPiBH+IAc4QNyhA/IET4gR/iAHOEDcoQPyBE+IEf4gBzhA3KED8gRPiBH+IAc4QNyhA/I+QuxW0l0pRqCiAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = clf(torch.Tensor(np.array(Image.open(\"/content/Screenshot 2024-04-18 214216_resized.png\").convert('L')).flatten().reshape(-1, 784)))"
      ],
      "metadata": {
        "id": "Z4NiD4vgmMX8"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.argmax(prediction).item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgwIfcAYWIuO",
        "outputId": "f1dfe84b-35b5-43bf-b2ea-8743c6c250e2"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 200
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "clGWNeyrYxte"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}